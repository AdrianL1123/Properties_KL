


from selenium import webdriver
from selenium.webdriver.common.by import By
import time
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd 
import numpy as np


# driver = webdriver.Chrome()
# driver.get("https://www.iproperty.com.my/sale/penang/all-residential/")

# time.sleep(3) 

# for i in range(25):
#     try:
#         # property_container = driver.find_element(By.XPATH, ".//div[@class='ListingsListstyle__ListingResultPage-iIneXB dBXYzA']")
#         property_container = driver.find_element(By.XPATH, "//ul[@class='ListingsListstyle__ListingsListContainer-dAfITF hkxQlK listing-list']")
#         print(property_container)
#         properties = property_container.find_elements(By.CSS_SELECTOR, ".ListingsListstyle__ListingListItemWrapper-hjHtwj.eUjjMH.sale-102366737")
        
#         properties[i].click()
#         time.sleep(2)  # Wait for the new page to load
        
#         # Extract the property name using the correct selector
#         property_name = WebDriverWait(driver, 10).until(
#             EC.presence_of_element_located((By.TAG_NAME, "h1"))
#         ).text
        
#         property_address = WebDriverWait(driver, 10).until(
#             EC.presence_of_element_located((By.TAG_NAME, "h3"))
#         ).text

#         property_size = WebDriverWait(driver, 10).until(
#             EC.presence_of_element_located((By.XPATH, ".//div[@class='ListingDescriptionstyle__Headline-CtOKw gDpweD']"))
#         ).text

#         try:
#             show_more_button = WebDriverWait(driver, 10).until(
#                 EC.presence_of_element_located((By.XPATH, ".//div[@id='property-details']//a[contains(text(),'Show more')]"))
#             )
#             show_more_button.click()
#             time.sleep(1)  
#         except:
#             # print("No 'Show More' button found, or couldn't click it.")
#             print(0)

#         try:
#         # Extract the property details
#             property_details = WebDriverWait(driver, 5).until(
#             EC.presence_of_element_located((By.XPATH, ".//div[@id='property-details']"))
#             ).text
            
#         except: 
#             # print('No property details skipping for now.')
#             # same thing but just to clean data easier 
#             print(0)
        
#         # print(f"Property Name: {property_name}, Property Address: {property_address}, Property Size: {property_size}")
#         # print(f'Property Details: {property_details}')
        
#         driver.back()  # Go back to the listings page
#         time.sleep(3)
        
#     except Exception as e:
#         print(f"Error: {e}")
#         continue

# driver.quit()


# driver = webdriver.Chrome()
# driver.get("https://www.iproperty.com.my/sale/penang/all-residential/")
# time.sleep(3)

# try:
#     property_container = WebDriverWait(driver, 10).until(
#         EC.presence_of_element_located((By.XPATH, "//ul[@class='ListingsListstyle__ListingsListContainer-dAfITF hkxQlK listing-list']"))
#     )
#     properties = property_container.find_elements(By.XPATH, ".//li[contains(@class, 'ListingsListstyle__ListingListItemWrapper-hjHtwj')]")

#     print(f"Found {len(properties)} properties")

#     for prop in properties:
#         try:
#             property_name = prop.find_element(By.XPATH, ".//h2").text
#             property_price = prop.find_element(By.XPATH, "//li[@class='ListingPricestyle__ItemWrapper-etxdML ejAiy']").text
#             # property_details = prop.find_element(By.XPATH, "//p[contains(@class, 'ListingAttributesstyle__ListingAttrsDescriptionItemWrapper') and contains(@class, 'attributes-description-item')]").text
            
#             prop.click()
#             try:
#                 show_more_button = WebDriverWait(driver, 10).until(
#                     EC.presence_of_element_located((By.XPATH, ".//div[@id='property-details']//a[contains(text(),'Show more')]"))
#                 )
#                 show_more_button.click()
#                 time.sleep(1)  
#             except:
#                 # print("No 'Show More' button found, or couldn't click it.")
#                 print(0)
    
#             try:
#                 # Extract the property details
#                 property_details = WebDriverWait(driver, 10).until(
#                 EC.presence_of_element_located((By.XPATH, "//div[@id='property-details']"))
#                 ).text
                
#             except: 
#                 # print('No property details skipping for now.')
#                 # same thing but just to clean data easier 
#                 print(0)

#             driver.back()  # Go back to the listings page
#             time.sleep(2)
            
            
#             print(f"Property Name: {property_name}")
#             print(f"Price: {property_price}")
#             print(f"Details: {property_details}")
#             print("-" * 50)

#         except Exception as e:
#             print(f"Error extracting property details: {e}")

# except Exception as e:
#     print(f"Error: {e}")

# finally:
#     driver.quit()





df = pd.read_csv('mudah-apartment-kl-selangor.csv')
df.head()





df.columns


df.isna().sum()


df.info()





df_cleaned = df.copy()
df_cleaned.head(1)


df_cleaned = df_cleaned.drop(['ads_id', 'completion_year'], axis=1)


df_cleaned['prop_name'] = df_cleaned['prop_name'].fillna('unknown')


df_cleaned.drop(df_cleaned[df_cleaned['monthly_rent'] == 'RM 70 per month'].index,axis=0, inplace=True)
df_cleaned.drop(df_cleaned[df_cleaned['monthly_rent'] == 'RM 85 per month'].index,axis=0, inplace=True)
df_cleaned.drop(df_cleaned[df_cleaned['monthly_rent'] == 'RM 80 per month'].index,axis=0, inplace=True)
df_cleaned.drop(df_cleaned[df_cleaned['monthly_rent'] == 'RM 90 per month'].index,axis=0, inplace=True)
df_cleaned.drop(df_cleaned[df_cleaned['size'] == '1 sq.ft.'].index,axis=0, inplace=True)


# replacing all the unwanted strings in data and eliminating the whitespace with regex 
df_cleaned['monthly_rent(RM)'] = df_cleaned['monthly_rent'].str.replace('RM', '').str.replace('per month', '').str.replace(r'\s+', '', regex=True).fillna(0).astype(float)



df_cleaned['monthly_rent(RM)'] = df_cleaned['monthly_rent(RM)'].fillna(df_cleaned['monthly_rent(RM)'].mean())


df_cleaned['rooms']


df_cleaned['monthly_rent'].unique()


df_cleaned['monthly_rent(RM)'].isna().sum()


df_cleaned.info()


df_cleaned = df_cleaned.drop('monthly_rent', axis=1)


# from sklearn.preprocessing import LabelEncoder
# label_encoder = LabelEncoder()

# objects = df_cleaned.select_dtypes(include='object')
# for col in objects:
#     df_cleaned[col] = label_encoder.fit_transform(objects[col])


df_cleaned['bathroom'] = df_cleaned['bathroom'].fillna(0).astype(int)
df_cleaned['bathroom']


df_cleaned['parking'] = df_cleaned['parking'].fillna(0).astype(int)
df_cleaned['parking']


df_cleaned.furnished = df_cleaned.furnished.replace(np.nan, 'unknown')
df_cleaned.furnished.isna().sum()


df_cleaned.facilities = df_cleaned.facilities.replace(np.nan, 'unknown')
df_cleaned.facilities.isna().sum()


df_cleaned.additional_facilities = df_cleaned.additional_facilities.replace(np.nan, 'unknown')
df_cleaned.additional_facilities.isna().sum()








df_cleaned.columns








df_cleaned = df_cleaned.reset_index()


normal_facilities = df_cleaned['facilities'].str.split(',', expand=True)
normal_facilities = normal_facilities.fillna('na')
normal_facilities = normal_facilities.reset_index()
normal_facilities

extra_facilities = df_cleaned['additional_facilities'].str.split(',', expand=True).fillna('na').reset_index()
extra_facilities

# total_facilities = pd.concat([normal_facilities, extra_facilities], axis=1)
total_facilities = pd.merge(normal_facilities, extra_facilities, how="inner", on=["index", "index"])
total_facilities


fac_col_name = total_facilities.columns
new_fac_col_names = ['facility'+ str(i) for i in range(0,len(fac_col_name))]
total_facilities.columns = new_fac_col_names
total_facilities.rename(columns={'facility0': 'index'}, inplace=True)
total_facilities.head()


df_new = pd.merge(df_cleaned, total_facilities, how="inner", on=["index", "index"])
df_new = df_new.drop(['index'], axis=1)
df_new.columns


from sklearn.preprocessing import OneHotEncoder
import pandas as pd

columns_needed = [
    'facility1', 'facility2', 'facility3', 'facility4', 'facility5',
    'facility6', 'facility7', 'facility8', 'facility9', 'facility10',
    'facility11', 'facility12', 'facility13', 'facility14', 'facility15',
    'facility16', 'facility17', 'facility18', 'facility19', 'facility20'
]

encoder = OneHotEncoder(sparse_output=False, drop='first')
encoded_array = encoder.fit_transform(df_new[columns_needed])
encoded_feature_names = encoder.get_feature_names_out(columns_needed)
encoded_df = pd.DataFrame(encoded_array, columns=encoded_feature_names)

encoded_df = encoded_df.astype(int)
# regex from chatgpt
encoded_df.columns = encoded_df.columns.str.replace(r'facility\d+_', '', regex=True)

# combine both new and encoded data 
df_new = pd.concat([df_new, encoded_df], axis=1)
df_new.head()


df_new = df_new.drop(['facility1', 'facility2', 'facility3', 'facility4', 'facility5',
    'facility6', 'facility7', 'facility8', 'facility9', 'facility10',
    'facility11', 'facility12', 'facility13', 'facility14', 'facility15',
    'facility16', 'facility17', 'facility18', 'facility19', 'facility20'], axis=1)


round(df_new.groupby(['property_type', 'facilities', 'additional_facilities'])['monthly_rent(RM)'].mean().sort_values(ascending=False).reset_index()).head(6)





round(df_new.groupby(['property_type', 'parking'])['monthly_rent(RM)'].mean().sort_values(ascending=False).reset_index())








df_new.groupby(['property_type', 'rooms'])['monthly_rent(RM)'].mean().sort_values(ascending=False).round().reset_index().head(10)








round(df_new.groupby(['property_type', 'Security'])['monthly_rent(RM)'].mean().sort_values(ascending=False).reset_index())








AveragePrice = df_new.groupby(['region', 'property_type'])['monthly_rent(RM)'].mean().reset_index()
round(AveragePrice)








df_new = pd.read_csv('featured_data.csv')
df_new.head()








df_new.head(3)





import plotly.express as px
AveragePrice = df_new.groupby(['region'])['monthly_rent(RM)'].mean().reset_index()


fig = px.bar(
    AveragePrice, 
    x='region',  
    y='monthly_rent(RM)', 
    title='Distribution of Average Price Based on Region', 
    labels={'region': 'Region', 'monthly_rent(RM)': 'Average Monthly Rent (RM)'}
)

fig.show()








AverageWithSecurity = df_new.groupby('Security')['monthly_rent(RM)'].mean().reset_index()

fig = px.bar(
    AverageWithSecurity, 
    y='monthly_rent(RM)',  
    x='Security', 
    title='Distribution of Average Price Based on Region', 
    labels={'monthly_rent(RM)': 'Rent', 'Security': 'Security'}
)

fig.show()





AveragePropertyType = df_new.groupby('property_type')['monthly_rent(RM)'].mean().sort_values(ascending=False).reset_index()
fig = px.bar(
    AveragePropertyType.round(), 
    y='monthly_rent(RM)',  
    x='property_type', 
    width= 900,
    height= 600,
    title='Distribution of Average Price Based on Property type', 
    labels={'monthly_rent(RM)': 'Rent', 'property_type': 'Property Type'}
)

fig.show()








df_new.rooms.unique()


AverageRooms = df_new.groupby('rooms')['monthly_rent(RM)'].mean().sort_values(ascending=False).reset_index()
fig = px.bar(
    AverageRooms.round(), 
    y='monthly_rent(RM)',  
    x='rooms', 
    # width= 900,
    # height= 900,
    title='Distribution of Average Price Based on Rooms', 
    labels={'monthly_rent(RM)': 'Rent', 'rooms': 'Rooms'}
)

fig.show()








apartments_only = df_new[df_new['property_type'] == 'Apartment']

apartments_avg_rent = apartments_only.groupby(['rooms'])['monthly_rent(RM)'].mean().sort_values(ascending=False).reset_index()

fig = px.bar(
    apartments_avg_rent, 
    x='rooms', 
    y='monthly_rent(RM)',  
    # width=900,
    # height=600,
    title='Distribution of Average Rent for Apartments Based on Number of Rooms', 
    labels={'monthly_rent(RM)': 'Rent (RM)', 'rooms': 'Number of Rooms'},
)

fig.show()








# Note that some properties that are few 100k and above are maybe to buy not to rent properties


parking = df_new.groupby('parking')['monthly_rent(RM)'].mean().round().reset_index()
px.bar(parking, x='parking', y='monthly_rent(RM)',  
       title='Average Rent Based on Parking Space', hover_data=['parking'], 
        labels={'monthly_rent(RM)': 'Average Rent (RM)'})








region_property_type = df_new.groupby(['property_type', 'region'])['monthly_rent(RM)'].mean().reset_index()
region_property_type
fig = px.bar(
    region_property_type, 
    x='property_type', 
    y='monthly_rent(RM)',  
    width=900,
    height=600,
    title='Distribution of Average Price Based on Property Type and Region', 
    labels={'monthly_rent(RM)': 'Rent (RM)', 'property_type': 'Property Type', 'region': 'Region'},
    hover_data=['region'],
    color='region'
)

fig.show()








apartment_selangor_mean_rent = df_new[(df_new['property_type'] == 'Apartment') & (df_new['region'] == 'Selangor')]['monthly_rent(RM)']
apartment_kl_mean_rent = df_new[(df_new['property_type'] == 'Apartment') & (df_new['region'] == 'Kuala Lumpur')]['monthly_rent(RM)']
apartment_selangor_mean_rent,apartment_kl_mean_rent


# H0 - Monthly Rent for Apartments is Selangor is not Lower than KL
# HA = Monthly Rent for Apartments is Selangor is Lower than KL


from scipy import stats 

t_test,p_val = stats.ttest_ind(apartment_selangor_mean_rent, 
                apartment_kl_mean_rent,nan_policy='omit', axis=0)
t_test,p_val


if p_val < 0.05:
    print("Reject the null hypothesis: The average rent for apartments in Selangor is significantly lower than in KL.")
else:
    print("Fail to reject the null hypothesis: No significant difference in average rent for apartments in Selangor and KL.")

















import pandas as pd 
import numpy as np
df_new = pd.read_csv('featured_data.csv')
df_new.head()


# from sklearn.preprocessing import LabelEncoder
# encoder = LabelEncoder()
# df_new['property_type'] = encoder.fit_transform(df_new['property_type'])
# df_new['region'] = encoder.fit_transform(df_new['region'])
# df_new['rooms'] = encoder.fit_transform(df_new['rooms'])


from sklearn.preprocessing import StandardScaler,MinMaxScaler
scaler = StandardScaler()
minMaxScaler = MinMaxScaler()

x = df_new.drop('monthly_rent(RM)', axis=1)
# y = scaler.fit_transform(df_new[['monthly_rent(RM)']]).ravel()
# y = minMaxScaler.fit_transform(df_new[['monthly_rent(RM)']]).ravel()
y = df_new['monthly_rent(RM)']


from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=12)
# x_train.shape, x_test.shape, y_train.shape, y_test.shape

# x_train['size'] = scaler.fit_transform(x_train[['size']])


# from sklearn.preprocessing import LabelEncoder, OneHotEncoder
# encoder = LabelEncoder()
# x_train = scaler.fit_transform(x_train)
# x_test = scaler.transform(x_test)


# from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

need_scale = ['size']
chosen_columns = ['property_type', 'region']
preprocessor = make_column_transformer(
    (StandardScaler(), need_scale),
    (OneHotEncoder(drop='first', sparse_output=False), chosen_columns)
    # (LabelEncoder(), chosen_columns)
)
preprocessor


# Linear Regression Models
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge, Lasso, ElasticNet

# Tree mou Models
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from xgboost import XGBRegressor

models = [
    LinearRegression(),
    Ridge(),
    Lasso(),
    DecisionTreeRegressor(),
    RandomForestRegressor(),
    GradientBoostingRegressor()
]






from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

def evaluate_model(model, x_train, x_test,y_train, y_test):
    model.fit(x_train,y_train)
    y_pred = model.predict(x_test)
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred) 
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)
    return mae,r2, rmse


#  # comparing which model is better
from sklearn.pipeline import Pipeline
from sklearn.model_selection import cross_val_score
results = []
for model in models:
    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('regressor', model)
    ])
    mae,rmse,r2 = evaluate_model(pipeline, x_train, x_test, y_train, y_test)
    cv_scores = cross_val_score(pipeline, x, y, cv=5, scoring='neg_mean_squared_error')
    cv_rmse = np.sqrt(-cv_scores.mean())
    results.append({
        'Model': model,
        'MAE': mae,
        "RMSE": rmse,
        'R2': r2,
        'Cross_V RMSE': cv_rmse,
    })
    print(model)


results = pd.DataFrame(results)
results








# modelz = DecisionTreeRegressor(random_state=12)

# param_grid = {
#     'max_depth': [3, 5, 10, None],                
#     'min_samples_split': [2, 10, 20],            
#     'min_samples_leaf': [1, 5, 10],              
#     'max_features': [None, 'sqrt', 'log2'],      
#     'criterion': ['squared_error','absolute_error'], 
# }

# grid_search = GridSearchCV(estimator=modelz, param_grid=param_grid, 
#                            cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')

# grid_search.fit(x_train, y_train)

# print(f"Best Parameters: {grid_search.best_params_}")
# print(f"Best Score: {grid_search.best_score_}")





from sklearn.tree import DecisionTreeRegressor
from sklearn.pipeline import Pipeline
from sklearn.model_selection import cross_val_score
import numpy as np

best_model = DecisionTreeRegressor(
    random_state=12, 
    criterion='absolute_error', 
    max_depth=10,
    max_features='sqrt',
    min_samples_leaf=1,
    min_samples_split=10
)

resultz = []

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('regressor', best_model)
])

mae, rmse, r2 = evaluate_model(pipeline, x_train, x_test, y_train, y_test)

cv_scores = cross_val_score(pipeline, x_train, y_train, cv=5, scoring='neg_mean_squared_error')
cv_rmse = np.sqrt(-cv_scores.mean())

resultz.append({
    'Model': 'DecisionTreeRegressor',  
    'MAE': mae,
    'RMSE': rmse,
    'R2': r2,
    'Cross_V RMSE': cv_rmse,
})

resultz = pd.DataFrame(resultz)
resultz








import pickle 

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('regressor', DecisionTreeRegressor(
    random_state=12, 
    criterion='absolute_error', 
    max_depth=10,
    max_features='sqrt',
    min_samples_leaf=1,
    min_samples_split=10)),
])
pipeline.fit(x_train, y_train)

with open('DecisionTreeRegressor.pkl', 'wb') as file:
    pickle.dump(pipeline, file)


x_train.columns


{col: x_train[col].unique() for col in x_train.columns}


y_pred = pipeline.predict(x_test)  
print(f"Example Predictions: {y_pred[:10]}")


import plotly.express as px
fig = px.scatter(df_new, x='rooms', y='monthly_rent(RM)', color='property_type', title='Rooms vs Monthly Rent')
fig.show()


fig = px.box(df_new, x='region', y='monthly_rent(RM)', title='Monthly Rent by Region')
fig.show()


df_facilities = df_new[['Gymnasium', 'Lift', 'Minimart', 'Sauna', 'Security', 'Swimming Pool']].sum()
fig = px.bar(df_facilities, title='Facilities Availability Across Properties')
fig.show()



